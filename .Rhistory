index = append(index, i)
}
if (list.lift[i] %in% unique(wideorder$wine)) {
index.lift = append(index.lift, i)
}
}
order.rules.meat.df <- order.rules.meat.df[index,]
order.rules.meat.df.lift <- order.rules.meat.df.lift[index.lift,]
#Ensuring only the meat with the highest confidence/lift is represented
unique.meats.df <- order.rules.meat.df[match(unique(order.rules.meat.df$lhs), order.rules.meat.df$lhs),]
unique.meats.df <- unique.meats.df[1:length(unique(wideorder$meat)),]
unique.meats.df.lift <- order.rules.meat.df.lift[match(unique(order.rules.meat.df.lift$lhs), order.rules.meat.df.lift$lhs),]
unique.meats.df.lift <- unique.meats.df.lift[1:length(unique(wideorder$meat)),]
plot(order.rules.meat.df)
plot(unique.meats.df)
plot(unique.meats.df.lift)
View(unique.meats.df)
View(unique.meats.df.lift)
library(datasets)
library(arules)
library(arulesViz)
library(ggplot2)
library(dplyr)
library(rpart)
library(rpart.plot)
library(TH.data)
library(ISLR2)
library(lattice)
library(stats)
library(rattle)
library(RColorBrewer)
library(caret)
library(ROCR)
library(tidyverse)
library(cluster)
library(factoextra)
library(gridExtra)
library(NbClust)
library(dendextend)
library(class)
library(ClustOfVar)
library(MASS)
library(kableExtra)
library(partykit)
library(dbscan)
library(ROCR)
#library(knitr)
#import data
churn <- read.csv("https://github.com/sjsimmo2/DataMining-Fall/raw/master/TelcoChurn.csv", header = TRUE)
head(churn)
#Check the variable types
str(churn)
#Check for rows with missing values and store them in a table
missing <- churn[!complete.cases(churn$TotalCharges),]
#set seed so we all get the same training, test, train data set
set.seed(1905)
#take 80/20 sample for train and test
ss <- sample(1:2,size=nrow(churn),replace=TRUE,prob=c(0.8,0.2))
train <- churn[ss==1,]
test <- churn[ss==2,]
#impute missing values with median and create missing variable
#Repeat for test and test using the training median
train$missing[is.na(train$TotalCharges)] <- 1
train$missing[is.na(train$missing)] <- 0
train$missing <- as.factor(train$missing)
train$missing[train$missing == 1]
train$TotalCharges[is.na(train$TotalCharges)] <- median(train$TotalCharges, na.rm = T)
train$missing <- as.character(train$missing)
test$missing[is.na(test$TotalCharges)] <- 1
test$missing[is.na(test$missing)] <- 0
test$missing <- as.character(test$missing)
train$TotalCharges[is.na(train$TotalCharges)] <- 0
test$TotalCharges[is.na(test$TotalCharges)] <- 0
train[!complete.cases(train),]
str(train)
#Create classification tree
class.tree = rpart(Churn ~ . - customerID, data=train, method='class',
parms = list(split='gini'))
summary(class.tree)
print(class.tree)
#Graph of the tree
rpart.plot(class.tree)
#Misclassification rate of training and test
tscores = predict(class.tree,type='class')
scores = predict(class.tree, test, type='class')
##Training misclassification rate:
sum(tscores!=train$Churn)/nrow(train)
### test data:
sum(scores!=test$Churn)/nrow(test)
#plot ROC Curve
tscores.prob <- predict(class.tree,type="prob")
pred_val <-prediction(tscores.prob[,2],train$Churn)
perf <- performance(pred_val, measure = "tpr", x.measure = "fpr")
plot(perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Classification Tree",
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
c.train <- train
c.train[sapply(c.train, is.character)] <- lapply(c.train[sapply(c.train, is.character)],
as.factor)
c.train$customerID <- as.character(c.train$customerID)
c.train$SeniorCitizen <- as.factor(c.train$SeniorCitizen)
str(c.train)
#run model
c.tree <- ctree(Churn ~ . - customerID, data=c.train)
c.tree
plot(c.tree)
#Check Misclassification rates
c.tscores = predict(c.tree,type='response')
c.scores = predict(c.tree, test, type='response')
##Training misclassification rate:
sum(c.tscores!=train$Churn)/nrow(train)
### test data:
sum(c.scores!=test$Churn)/nrow(test)
#plot ROC Curve
c.tscores.prob <- predict(c.tree,type="prob")
c.pred_val <-prediction(c.tscores.prob[,2],train$Churn)
c.perf <- performance(c.pred_val, measure = "tpr", x.measure = "fpr")
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
#plot ROC Curve
c.tscores.prob <- predict(c.tree, test, type="prob")
c.pred_val <-prediction(c.tscores.prob[,2],train$Churn)
c.perf <- performance(c.pred_val, measure = "tpr", x.measure = "fpr")
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
c.test <- test
c.test[sapply(c.test, is.character)] <- lapply(c.test[sapply(c.test, is.character)],
as.factor)
c.test$customerID <- as.character(c.test$customerID)
c.test$SeniorCitizen <- as.factor(c.test$SeniorCitizen)
c.tscores.prob <- predict(c.tree, test, type="prob")
c.pred_val <-prediction(c.tscores.prob[,2],train$Churn)
c.perf <- performance(c.pred_val, measure = "tpr", x.measure = "fpr")
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
### test data:
sum(c.scores!=c.test$Churn)/nrow(c.test)
#plot ROC Curve
c.tscores.prob <- predict(c.tree, c.test, type="prob")
c.pred_val <-prediction(c.tscores.prob[,2],train$Churn)
c.perf <- performance(c.pred_val, measure = "tpr", x.measure = "fpr")
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
c.tscores.prob <- predict(c.tree, c.test, type="prob")
c.pred_val <-prediction(c.tscores.prob[,2],c.train$Churn)
c.perf <- performance(c.pred_val, measure = "tpr", x.measure = "fpr")
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
View(c.tscores.prob)
c.tscores.prob <- predict(c.tree, c.test, type="prob")
c.pred_val <-prediction(c.tscores.prob[,2],c.test$Churn)
c.perf <- performance(c.pred_val, measure = "tpr", x.measure = "fpr")
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
### test data:
sum(c.scores!=c.test$Churn)/nrow(c.test)
##Training misclassification rate:
sum(c.tscores!=train$Churn)/nrow(train)
class.tree = rpart(Churn ~ . - customerID, data=train, method='class',
parms = list(split='gini'))
summary(class.tree)
print(class.tree)
#Graph of the tree
rpart.plot(class.tree)
#Misclassification rate of training and test
tscores = predict(class.tree,type='class')
scores = predict(class.tree, test, type='class')
##Training misclassification rate:
sum(tscores!=train$Churn)/nrow(train)
### test data:
sum(scores!=test$Churn)/nrow(test)
#plot ROC Curve
tscores.prob <- predict(class.tree,test,type="prob")
pred_val <-prediction(tscores.prob[,2],train$Churn)
perf <- performance(pred_val, measure = "tpr", x.measure = "fpr")
plot(perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Classification Tree",
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
#Create classification tree
class.tree = rpart(Churn ~ . - customerID, data=train, method='class',
parms = list(split='gini'))
#import data
churn <- read.csv("https://github.com/sjsimmo2/DataMining-Fall/raw/master/TelcoChurn.csv", header = TRUE)
head(churn)
#Check the variable types
str(churn)
#Check for rows with missing values and store them in a table
missing <- churn[!complete.cases(churn$TotalCharges),]
#set seed so we all get the same training, test, train data set
set.seed(1905)
#take 80/20 sample for train and test
ss <- sample(1:2,size=nrow(churn),replace=TRUE,prob=c(0.8,0.2))
train <- churn[ss==1,]
test <- churn[ss==2,]
#impute missing values with median and create missing variable
#Repeat for test and test using the training median
train$missing[is.na(train$TotalCharges)] <- 1
train$missing[is.na(train$missing)] <- 0
train$missing <- as.factor(train$missing)
train$missing[train$missing == 1]
train$TotalCharges[is.na(train$TotalCharges)] <- median(train$TotalCharges, na.rm = T)
train$missing <- as.character(train$missing)
test$missing[is.na(test$TotalCharges)] <- 1
test$missing[is.na(test$missing)] <- 0
test$missing <- as.character(test$missing)
train$TotalCharges[is.na(train$TotalCharges)] <- 0
test$TotalCharges[is.na(test$TotalCharges)] <- 0
train[!complete.cases(train),]
#Create classification tree
class.tree = rpart(Churn ~ . - customerID, data=train, method='class',
parms = list(split='gini'))
#Create classification tree
class.tree = rpart(Churn ~ . - customerID, data=train, method='class',
parms = list(split='information'))
performance(c.pred_val, measure = "auc")@y.values
c.perf <- performance(c.pred_val, measure = "tpr", x.measure = "fpr")
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
sub = "AUROC = "
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
sub = "AUROC = ",
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
sub = paste("AUROC = " + performance(pred_val, measure = "auc")@y.values),
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
sub = paste("AUROC = " + performance(c.pred_val, measure = "auc")@y.values),
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
sub = paste("AUROC = " + performance(c.pred_val, measure = "auc")@y.values[1][[1]]),
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
performance(c.pred_val, measure = "auc")@y.values[1]
performance(c.pred_val, measure = "auc")@y.values[[1]]
performance(c.pred_val, measure = "auc")@y.values[[1]][1]
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
sub = paste("AUROC = " + performance(c.pred_val, measure = "auc")@y.values[[1]]),
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
performance(c.pred_val, measure = "auc")@y.values[[1]][1]
performance(c.pred_val, measure = "auc")@y.values[[1]]
as.numeric(performance(c.pred_val, measure = "auc")@y.values[[1]])
c.auroc<-as.numeric(performance(c.pred_val, measure = "auc")@y.values[[1]])
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
sub = paste("AUROC = " + c.auroc),
xlab = "True Positive Rate",
ylab = "False Positive Rate")
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
sub = paste("AUROC = " + c.auroc),
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
sub = print("AUROC = " + c.auroc),
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
plot(c.perf, lwd = 3, col = "dodgerblue3",
main = "ROC Cruve of Recursive Partitioning Tree",
sub = paste("AUROC = 0.8288112"),
xlab = "True Positive Rate",
ylab = "False Positive Rate")
abline(a = 0, b = 1, lty = 3)
#load data
df <- read.csv("https://raw.githubusercontent.com/felicitimilne/bluefall2hwteam17/main/hrl_load_metered.csv")
head(df)
df2 <- read.csv("https://github.com/felicitimilne/bluefall2hwteam17/blob/main/hrl_load_metered%20-%20test1.csv")
head(validation)
head(df2)
df2 <- read.csv("https://github.com/felicitimilne/bluefall2hwteam17/raw/main/hrl_load_metered%20-%20test1.csv")
head(df2)
rbind(df,df2)
df3 <- rbind(df,df2)
View(df3)
View(df2)
validation <- read.csv("https://github.com/felicitimilne/bluefall2hwteam17/raw/main/hrl_load_metered%20-%20test2.csv")
#get rid of useless variables
df3 <- df[,c(1,6)]
validation <- validation[,c(1,6)]
library(dplyr)
library(ggfortify)
library(lubridate)
library(tseries)
library(forecast)
library(haven)
library(fma)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(ggplot2)
library(seasonalview)
library(aTSA)
library(imputeTS)
library(prophet)
#load data
df <- read.csv("https://raw.githubusercontent.com/felicitimilne/bluefall2hwteam17/main/hrl_load_metered.csv")
head(df)
df2 <- read.csv("https://github.com/felicitimilne/bluefall2hwteam17/raw/main/hrl_load_metered%20-%20test1.csv")
head(df2)
df3 <- rbind(df,df2)
validation <- read.csv("https://github.com/felicitimilne/bluefall2hwteam17/raw/main/hrl_load_metered%20-%20test2.csv")
#get rid of useless variables
df3 <- df[,c(1,6)]
validation <- validation[,c(1,6)]
#Change variable to a date time object
df3$datetime_beginning_ept <- mdy_hm(df3$datetime_beginning_ept, tz = Sys.timezone())
validation$datetime_beginning_ept <- mdy_hm(validation$datetime_beginning_ept, tz = Sys.timezone())
#Impute the average of previous and next observation to fix the zeros for DLS
df3[c(5280:5290),]
df3[5283,2] <- 904.2965
df3[c(14180:14190),]
df3[14187,2] <- 844.047
# create time series object
energy <- ts(df3[,2], start = 2019, frequency = 24) # frequency = 24 hours * 365.25 days in a year
# autoplot
autoplot(energy) +
ggtitle("Energy Usage") +
xlab("Time") +
ylab("Energy")
#decomposition plot
decomp_stl <- stl(energy, s.window = 7)
plot(decomp_stl)
autoplot(decomp_stl)
#subseries plot that plots the averages of the seasons
ggsubseriesplot(energy)
prophet.data <- data.frame(ds = df3$datetime_beginning_ept, y = df3$mw)
View(prophet.data)
prophet.data <- data.frame(ds = df3$datetime_beginning_ept, y = df3$mw)
Prof <- prophet()
Prof <- add_country_holidays(Prof, "US")
Prof <- add_seasonality(Prof, name='weekly', period=7, fourier.order=6)
Prof <- fit.prophet(Prof, prophet.data)
prophet.data <- data.frame(ds = df3$datetime_beginning_ept, y = df3$mw)
Prof <- prophet()
Prof <- add_country_holidays(Prof, "US")
Prof <- add_seasonality(Prof, name='daily', period=7, fourier.order=6)
Prof <- fit.prophet(Prof, prophet.data)
Prof <- prophet()
Prof <- add_country_holidays(Prof, "US")
Prof <- add_seasonality(Prof, name='monthly', period=30.5, fourier.order=6)
Prof <- fit.prophet(Prof, prophet.data)
forecast.data <- make_future_dataframe(Prof, periods = 128, freq = 'hour')
forecast.data <- make_future_dataframe(Prof, periods = 168, freq = 'hour')
plot(Prof, predict(Prof, forecast.data))
View(forecast.data)
View(prophet.data)
forecast.data <- make_future_dataframe(Prof, periods = 168, freq = 'hour')
View(forecast.data)
View(df3)
plot(Prof, forecast.data)
plot(forecast.data)
predict(Prof, forecast.data)$yhat
plot(forecast.data,predict(Prof, forecast.data))
plot(Prof, predict(Prof, forecast.data))
# Calculate prediction errors from forecast
Prophet.error <- validation - tail(predict(Prof, forecast.data)$yhat, 168)
Prophet.error <- validation - tail(predict(Prof, forecast.data)$yhat, 168)
# libraries
library(dplyr)
library(ggfortify)
library(lubridate)
library(tseries)
library(forecast)
library(haven)
library(fma)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(ggplot2)
library(seasonalview)
library(aTSA)
library(imputeTS)
library(prophet)
Prophet.error <- validation - tail(predict(Prof, forecast.data)$yhat, 168)
Prophet.MAE <- mean(abs(Prophet.error))
Prophet.MAPE <- mean(abs(Prophet.error)/abs(test))*100
Prophet.MAE
Prophet.MAPE
View(Prophet.error)
Prophet.MAE <- mean(abs(Prophet.error$mw))
Prophet.MAPE <- mean(abs(Prophet.error$mw)/abs(test$mw))*100
Prophet.MAE
Prophet.MAPE
Prophet.MAE <- mean(abs(Prophet.error$mw))
Prophet.MAPE <- mean(abs(Prophet.error$mw)/abs(validation$mw))*100
Prophet.MAE
Prophet.MAPE
ta_metrics <- read.csv("https://github.com/felicitimilne/bluefall2hwteam17/raw/main/yearly_sent_metrics.csv")
library(tidyverse)
library(ggplot2)
library(gghighlight)
ta_metrics <- ta_metrics %>% mutate(Avg.Anger = -1 * Avg.Anger, Avg.Disgust = -1 * Avg.Disgust,
Avg.Fear = -1 * Avg.Fear, Avg.Neg = -1 * Avg.Neg, Avg.Sadness = -1 * Avg.Sadness) %>%
rename(Neg.Anger = Avg.Anger, Neg.Disgust = Avg.Disgust, Neg.Fear = Avg.Fear, Neg.Negative = Avg.Neg, Neg.Sadness = Avg.Sadness,
Pos.Anticipation = Avg.Antic, Pos.Joy = Avg.Joy, Pos.Positive = Avg.Pos, Pos.Surprise = Avg.Surprise, Pos.Trust = Avg.Trust)
ggplot(data = ta_metrics) + geom_line(aes(x = Year, y = Avg.Exp.Valence), color = "#648fff") +
scale_x_continuous(breaks = seq(min(ta_metrics$Year),max(ta_metrics$Year),by=1)) +
geom_line(aes(x = Year, y = rep(0, nrow(ta_metrics))), color = "#ffb000", linetype = "dashed") +
geom_point(aes(x = 2019, y = Avg.Exp.Valence[14]), color = "#dc267f")
tam_avg <- data.frame()
for (i in 9:19) {
tam_avg <- rbind(tam_avg, c(colnames(ta_metrics)[i], mean(ta_metrics[,i]), "Overall Average"))
}
colnames(tam_avg) <- c("Metric", "Value", "Type")
tam_long <- ta_metrics %>% pivot_longer(cols = -1, names_to = "Metric")
tam_2019 <- tam_long %>% filter(X == 13) %>% dplyr::select(-X) %>%
mutate(Type = "2019") %>% rename(Value = value)
tam_2019 <- tam_2019[8:18,]
tam_2019 <- rbind(tam_2019, data.frame(tam_avg))
tam_2019 <- tam_2019 %>% mutate(Value = as.numeric(Value))
ggplot(data = tam_2019) + geom_bar(aes(x = Metric, y = Value , fill = Type), position = "dodge", stat = "identity") +
scale_x_discrete(labels = c("Valence", "Anger", "Disgust", "Fear", "Negativity", "Sadness", "Anticipation", "Joy", "Positivity", "Surprise", "Trust")) +
ylim(c(-0.2, 0.2)) + theme(axis.text.x = element_text(angle = 45, vjust = 0.5))
tam_2020 <- tam_long %>% filter(X == 14) %>% dplyr::select(-X) %>%
mutate(Type = "2020") %>% rename(Value = value)
tam_2020 <- tam_2020[8:18,]
tam_2021 <- tam_long %>% filter(X == 15) %>% dplyr::select(-X) %>%
mutate(Type = "2021") %>% rename(Value = value)
tam_2021 <- tam_2021[8:18,]
tam_2019_20_21 <- rbind(tam_2019, tam_2020, tam_2021, data.frame(tam_avg))
tam_2019_20_21 <- tam_2019_20_21 %>% mutate(Value = as.numeric(Value))
ggplot(data = tam_2019_20_21) + geom_bar(aes(x = Metric, y = Value , fill = Type), position = "dodge", stat = "identity") +
geom_segment(aes(x = 1, xend = 1, y = -0.25, yend = 0.25), color = "#bbbbbb") +
scale_x_discrete(labels = c("Valence", "Anger", "Disgust", "Fear", "Negativity", "Sadness", "Anticipation", "Joy", "Positivity", "Surprise", "Trust")) +
scale_fill_manual(labels = c("2019", "2020", "2021", "Overall Average"), values = c("#648fff", "#ffb000", "#dc267f", "#888888")) +
ylim(c(-0.2, 0.2)) + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), legend.title = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
labs(x = "Emotion", y = "Average Value", title = "Late-Year Emotion Analysis")
from_2012 <- ta_metrics %>% filter(Year >= 2012)
from_2012_long <- from_2012 %>% mutate(Avg.Exp.Valence = Avg.Exp.Valence + 0.5) %>% dplyr::select(c(2, 19, 21:22)) %>% pivot_longer(cols = -1, names_to = "Metric")
to_2012 <- ta_metrics %>% filter(Year <= 2011)
to_2012_long <- to_2012 %>% mutate(Avg.Exp.Valence = Avg.Exp.Valence + 0.5) %>% dplyr::select(c(2, 19, 21)) %>% pivot_longer(cols = -1, names_to = "Metric")
long_sent <- ta_metrics %>% mutate(Avg.Exp.Valence = Avg.Exp.Valence + 0.5) %>% dplyr::select(c(2, 19, 21)) %>% pivot_longer(cols = -1, names_to = "Metric")
ggplot(data = long_sent, aes(x = Year, y = value, color = Metric)) + geom_line() +
scale_y_continuous(sec.axis = sec_axis(~.-0.5, name = "Expanded Valence")) +
theme(legend.title = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
scale_color_manual(labels = c("Expanded Valence", "Global Sentiment Indicator"), values = c("#648fff", "#ffb000")) +
labs(x = "Year", y = "Combined Sentiment Index", col = "Sentiment Metric", title = "Popular Song Sentiment vs Global Economic Sentiment")
ggplot(data = to_2012_long, aes(x = Year, y = value, color = Metric)) + geom_line() +
scale_y_continuous(sec.axis = sec_axis(~.-0.5, name = "Expanded Valence")) +
theme(legend.title = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
scale_color_manual(labels = c("Expanded Valence", "Global Sentiment Indicator"), values = c("#648fff", "#ffb000")) +
labs(x = "Year", y = "Combined Sentiment Index", col = "Sentiment Metric", title = "Popular Song Sentiment vs Global Economic Sentiment until 2012")
twitter_only <- from_2012_long %>% filter(Metric != "Avg.GS.Indicator")
ggplot(data = twitter_only, aes(x = Year, y = value, color = Metric)) + geom_line() +
scale_y_continuous(sec.axis = sec_axis(~.-0.5, name = "Expanded Valence")) +
theme(legend.title = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
scale_color_manual(labels = c("Expanded Valence", "Twitter Sentiment"), values = c("#648fff", "#dc267f")) +
labs(x = "Year", y = "Combined Sentiment Index", col = "Sentiment Metric", title = "Popular Song Sentiment vs Twitter Sentiment")
comb_metr_df <- data.frame(rbind(to_2012_long, twitter_only)) %>% mutate(Metric2 = ifelse(Metric == "Avg.Exp.Valence", Metric, "Sent.Index"))
ggplot(data = comb_metr_df, aes(x = Year, y = value, color = interaction(Metric, Metric2))) + geom_line() +
scale_y_continuous(sec.axis = sec_axis(~.-0.5, name = "Expanded Valence")) +
theme(legend.title = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
geom_segment(aes(x = 2011, xend = 2012, y = comb_metr_df["value"][12,] + 0.001, yend = comb_metr_df["value"][14,] + 0.001), color = "#888888", linetype = 2) +
scale_color_manual(labels = c("Expanded Valence", "Global Sentiment Indicator", "Twitter Sentiment"), values = c("#648fff", "#ffb000", "#dc267f")) +
labs(x = "Year", y = "Combined Sentiment Index", col = "Sentiment Metric", title = "Popular Song Sentiment vs Combined Global Sentiment")
ggplot(data = ta_metrics) + geom_line(aes(x = Year, y = Avg.Exp.Valence), color = "#648fff") +
scale_x_continuous(breaks = seq(min(ta_metrics$Year),max(ta_metrics$Year),by=1)) +
geom_line(aes(x = Year, y = rep(0, nrow(ta_metrics))), color = "#ffb000", linetype = "dashed") +
geom_point(aes(x = 2019, y = Avg.Exp.Valence[14]), color = "#dc267f") +
geom_hline(y = mean(Avg.Exp.Valence))
ggplot(data = ta_metrics) + geom_line(aes(x = Year, y = Avg.Exp.Valence), color = "#648fff") +
scale_x_continuous(breaks = seq(min(ta_metrics$Year),max(ta_metrics$Year),by=1)) +
geom_line(aes(x = Year, y = rep(0, nrow(ta_metrics))), color = "#ffb000", linetype = "dashed") +
geom_point(aes(x = 2019, y = Avg.Exp.Valence[14]), color = "#dc267f") +
geom_hline(y = mean(ta_metrics$Avg.Exp.Valence))
ggplot(data = ta_metrics) + geom_line(aes(x = Year, y = Avg.Exp.Valence), color = "#648fff") +
scale_x_continuous(breaks = seq(min(ta_metrics$Year),max(ta_metrics$Year),by=1)) +
geom_line(aes(x = Year, y = rep(0, nrow(ta_metrics))), color = "#ffb000", linetype = "dashed") +
geom_point(aes(x = 2019, y = Avg.Exp.Valence[14]), color = "#dc267f")
